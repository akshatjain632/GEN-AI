{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention Mechanism Assignment (Graded): Text Classification with AG News Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your programming assignment on Self Attention Mechanism! You will build a Deep Learning Model with Self Attention Mechanism for text classification on the AG News Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this assignment, you will explore and implement self-attention mechanisms for text classification using the AG News dataset.\n",
    "\n",
    "- Your goal is to build and train a text classification model that utilizes self-attention to categorize news articles into predefined topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The AG News dataset is a collection of news articles categorized into four classes:\n",
    "    - World\n",
    "\n",
    "    - Sports\n",
    "    - Business\n",
    "    - Sci/Tech\n",
    "\n",
    "- The dataset consists of:\n",
    "    - 120,000 training examples\n",
    "    - 7,600 test examples\n",
    "\n",
    "- Each example in the dataset contains:\n",
    "    - Text: The news article text\n",
    "    - Label: An integer (0-3) representing the category of the news article\n",
    "\n",
    "- For more information about the AG News dataset, you can visit the following link: [AG News Dataset](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Preparation and Exploration**\n",
    "    - Explore the dataset structure, including the number of samples, class distribution, and text length statistics.\n",
    "    \n",
    "    - Implement a function to preprocess the text data, including tokenization and padding.\n",
    "\n",
    "2. **Implement a Self-Attention Layer**\n",
    "    - Create a custom Keras layer that implements the self-attention mechanism.\n",
    "\n",
    "    - The layer should take a sequence of word embeddings as input and output attention-weighted representations.\n",
    "\n",
    "    - Implement the attention score calculation and softmax normalization.\n",
    "\n",
    "3. **Build the Text Classification Model**\n",
    "\n",
    "    - Design a neural network architecture that incorporates the self-attention layer.\n",
    "    \n",
    "    - The model should include an embedding layer, the self-attention layer, and output layers for classification.\n",
    "    \n",
    "    - Compile the model with appropriate loss function and optimizer.\n",
    "\n",
    "4. **Train and Evaluate the Model**\n",
    "    - Split the training data into training and validation sets.\n",
    "\n",
    "    - Train the model on the training set and monitor its performance on the validation set.\n",
    "\n",
    "    - Implement early stopping to prevent overfitting.\n",
    "\n",
    "    - Evaluate the trained model on the test set and report accuracy and other relevant metrics.\n",
    "\n",
    "5. **Prediction and Interpretation**\n",
    "   - Use the trained model to make predictions on new, unseen reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only write code when you see any of the below prompts,\n",
    "\n",
    "    ```\n",
    "    # YOUR CODE GOES HERE\n",
    "    # YOUR CODE ENDS HERE\n",
    "    # TODO\n",
    "    ```\n",
    "\n",
    "- Do not modify any other section of the code unless tated otherwise in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from helpers.methods import load_data, plot_results, detect_and_set_device\n",
    "from tests.test_methods import test_vectorize_text, test_self_attention, test_create_model, test_train_model, test_evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AG News dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c2ab48a6d64ea5a71be995d250ef32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\arj64\\.cache\\huggingface\\hub\\datasets--ag_news. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a9549f02ca4178a76b430336bd9a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d68ab00b5f402f92353de086585815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5f580c7dcd441e93644376817117d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e5882995f4152a3ed76c0424b9ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Data Spit into Train and Validation Sets\n"
     ]
    }
   ],
   "source": [
    " # load data\n",
    "train_data, test_data = load_data()\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "print(\"Data Spit into Train and Validation Sets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Let's get to know about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53541</th>\n",
       "      <td>Support independent journalism Please donate n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41728</th>\n",
       "      <td>Stingy Falcons Defense Key to 3-0 Start (AP) A...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74819</th>\n",
       "      <td>Pak, Sri Lanka lock horns in Karachi Test toda...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106459</th>\n",
       "      <td>Villages tune in to digital trial Two villages...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63062</th>\n",
       "      <td>South African gold groups poised for merger A ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Class\n",
       "53541   Support independent journalism Please donate n...      1\n",
       "41728   Stingy Falcons Defense Key to 3-0 Start (AP) A...      2\n",
       "74819   Pak, Sri Lanka lock horns in Karachi Test toda...      2\n",
       "106459  Villages tune in to digital trial Two villages...      4\n",
       "63062   South African gold groups poised for merger A ...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the dataset: Testing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Number of training samples: 96000\n",
      "Number of test samples: 7600\n"
     ]
    }
   ],
   "source": [
    "# TODO: Number of samples\n",
    "train_samples = train_data.shape[0]\n",
    "test_samples = test_data.shape[0]\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(f\"Number of training samples: {train_samples}\")\n",
    "print(f\"Number of test samples: {test_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Class\n",
      "3    24089\n",
      "1    24044\n",
      "2    23942\n",
      "4    23925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Class distribution\n",
    "class_distribution = train_data['Class'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text length statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text length statistics:\n",
      "count    96000.000000\n",
      "mean       236.555656\n",
      "std         66.164717\n",
      "min        100.000000\n",
      "25%        196.000000\n",
      "50%        232.000000\n",
      "75%        266.000000\n",
      "max       1012.000000\n",
      "Name: Text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Text length statistics\n",
    "text_length_stats =train_data['Text'].apply(len).describe()\n",
    "\n",
    "print(\"\\nText length statistics:\")\n",
    "print(text_length_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing text length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText Length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         display(\n\u001b[0;32m     91\u001b[0m             figure_manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[0;32m     92\u001b[0m             metadata\u001b[38;5;241m=\u001b[39m_fetch_figure_metadata(figure_manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure)\n\u001b[0;32m     93\u001b[0m         )\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m formatter(obj)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\backend_bases.py:2161\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2161\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mget_tightbbox(\n\u001b[0;32m   2162\u001b[0m             renderer, bbox_extra_artists\u001b[38;5;241m=\u001b[39mbbox_extra_artists)\n\u001b[0;32m   2163\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(layout_engine, ConstrainedLayoutEngine) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m                 pad_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2165\u001b[0m             h_pad \u001b[38;5;241m=\u001b[39m layout_engine\u001b[38;5;241m.\u001b[39mget()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\figure.py:1783\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;66;03m# some axes don't take the bbox_extra_artists kwarg so we\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;66;03m# need this conditional....\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1783\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_tightbbox(\n\u001b[0;32m   1784\u001b[0m             renderer, bbox_extra_artists\u001b[38;5;241m=\u001b[39mbbox_extra_artists)\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1786\u001b[0m         bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:4395\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   4394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison \u001b[38;5;129;01mand\u001b[39;00m axis\u001b[38;5;241m.\u001b[39mget_visible():\n\u001b[1;32m-> 4395\u001b[0m         ba \u001b[38;5;241m=\u001b[39m martist\u001b[38;5;241m.\u001b[39m_get_tightbbox_for_layout_only(axis, renderer)\n\u001b[0;32m   4396\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ba:\n\u001b[0;32m   4397\u001b[0m             bb\u001b[38;5;241m.\u001b[39mappend(ba)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\artist.py:1411\u001b[0m, in \u001b[0;36m_get_tightbbox_for_layout_only\u001b[1;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;124;03mMatplotlib's `.Axes.get_tightbbox` and `.Axis.get_tightbbox` support a\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m*for_layout_only* kwarg; this helper tries to use the kwarg but skips it\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03mwhen encountering third-party subclasses that do not support it.\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor_layout_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_tightbbox(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:1336\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m   1334\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:2368\u001b[0m, in \u001b[0;36mXAxis._update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m \u001b[38;5;66;03m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[0;32m   2367\u001b[0m \u001b[38;5;66;03m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[1;32m-> 2368\u001b[0m bboxes, bboxes2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tick_boxes_siblings(renderer\u001b[38;5;241m=\u001b[39mrenderer)\n\u001b[0;32m   2370\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mget_position()\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_position \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:2161\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2159\u001b[0m axis \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_axis_map[name]\n\u001b[0;32m   2160\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 2161\u001b[0m tlb, tlb2 \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   2162\u001b[0m bboxes\u001b[38;5;241m.\u001b[39mextend(tlb)\n\u001b[0;32m   2163\u001b[0m bboxes2\u001b[38;5;241m.\u001b[39mextend(tlb2)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\text.py:381\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    379\u001b[0m clean_line, ismath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_math(line)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_line:\n\u001b[1;32m--> 381\u001b[0m     w, h, d \u001b[38;5;241m=\u001b[39m _get_text_metrics_with_cache(\n\u001b[0;32m    382\u001b[0m         renderer, clean_line, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fontproperties,\n\u001b[0;32m    383\u001b[0m         ismath\u001b[38;5;241m=\u001b[39mismath, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     w \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m=\u001b[39m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_text_metrics_with_cache_impl(\n\u001b[0;32m     70\u001b[0m     weakref\u001b[38;5;241m.\u001b[39mref(renderer), text, fontprop\u001b[38;5;241m.\u001b[39mcopy(), ismath, dpi)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m renderer_ref()\u001b[38;5;241m.\u001b[39mget_text_width_height_descent(text, fontprop, ismath)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:221\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[0;32m    220\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_font(prop)\n\u001b[1;32m--> 221\u001b[0m font\u001b[38;5;241m.\u001b[39mset_text(s, \u001b[38;5;241m0.0\u001b[39m, flags\u001b[38;5;241m=\u001b[39mget_hinting_flag())\n\u001b[0;32m    222\u001b[0m w, h \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m    223\u001b[0m d \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_descent()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Visualize text length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_data['Text'].hist(bins=50)\n",
    "plt.title('Distribution of Text Lengths in Training Set')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the vectorize_text function for preprocessing the text data.\n",
    "\n",
    "- Use the TextVectorization layer from TensorFlow/Keras to convert the text data into sequences of integers.\n",
    "\n",
    "- Set the maximum number of words in the vocabulary to 20,000 using the max_tokens parameter in TextVectorization.\n",
    "\n",
    "- Set the maximum length for the sequences to 100 using the output_sequence_length parameter in TextVectorization.\n",
    "\n",
    "- Adapt the vectorization layer to the training data using the adapt method, passing in the 'Text' column values from the train_data DataFrame.\n",
    "\n",
    "- Return the configured vectorize_layer for use in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Vectorization\n",
    "def vectorize_text(train_data, test_data):\n",
    "    max_features = 20000\n",
    "    sequence_length = 100\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    vectorize_layer=tf.keras.layers.TextVectorization(max_tokens=max_features,output_sequence_length=sequence_length)\n",
    "    vectorize_layer.adapt(train_data['Text'].values)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    test_vectorize_text(vectorize_layer)\n",
    "    \n",
    "    return vectorize_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Building the Self-Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Implement the SelfAttention class as a custom layer in TensorFlow/Keras.\n",
    "\n",
    "- Create a class that inherits from tf.keras.layers.Layer.\n",
    "\n",
    "- In the __init__ method:\n",
    "  - Initialize the parent class using super().\n",
    "  - Create three Dense layers: W1 and W2 with the specified number of units, and V with one unit.\n",
    "\n",
    "- Implement the call method to perform the self-attention mechanism:\n",
    "  - Calculate the attention scores using the W1, W2, and V layers.\n",
    "  - Apply softmax to get attention weights.\n",
    "  - Use the attention weights to create a context vector.\n",
    "  - Ensure the output shape is (batch_size, embedding_dim).\n",
    "\n",
    "- Add comments to explain the shape of tensors at each step of the attention mechanism.\n",
    "\n",
    "- Consider implementing a get_config method for serialization if you plan to save the model.\n",
    "\n",
    "- Test the layer with sample input to ensure it produces the expected output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAttention test passed\n"
     ]
    }
   ],
   "source": [
    "# Self-Attention Layer\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # TODO: inputs shape: (batch_size, seq_len, embedding_dim)\n",
    "        # TODO: score shape: (batch_size, seq_len, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(inputs) + self.W2(inputs)))\n",
    "        # TODO: attention_weights shape: (batch_size, seq_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # TODO: context_vector shape: (batch_size, embedding_dim)\n",
    "        context_vector = attention_weights * inputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector\n",
    "    \n",
    "test_self_attention(SelfAttention(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the create_model function to build the text classification model with self-attention.\n",
    "\n",
    "- Use the Sequential API from Keras to create the model.\n",
    "\n",
    "- Add the following layers in order:\n",
    "  1. The vectorize_layer as the first layer to process input text.\n",
    "  2. An Embedding layer with 20,000 input dimensions and 128 output dimensions.\n",
    "  3. A Bidirectional LSTM layer with 64 units, setting return_sequences=True.\n",
    "  4. The custom SelfAttention layer with 64 units.\n",
    "  5. A Dense layer with 64 units and ReLU activation.\n",
    "  6. A Dropout layer with a rate of 0.5 for regularization.\n",
    "  7. A final Dense layer with 4 units (one for each class) and softmax activation.\n",
    "\n",
    "- Compile the model with:\n",
    "  - The sparse categorical crossentropy loss function.\n",
    "  - The Adam optimizer.\n",
    "  - Accuracy as the metric to monitor.\n",
    "\n",
    "- Return the compiled model.\n",
    "\n",
    "- Consider adding a summary() call to print the model architecture for verification.\n",
    "\n",
    "- Ensure that the input and output shapes of each layer are compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def create_model(vectorize_layer):\n",
    "    embedding_dim =128\n",
    "    vocab_size=20000\n",
    "    units=64\n",
    "    num_classes=4\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "    model=Sequential([vectorize_layer,\n",
    "                     Embedding(input_dim=vocab_size,output_dim=embedding_dim),\n",
    "                     (LSTM(units,return_sequences=True)),\n",
    "                     SelfAttention(units),\n",
    "                     Dense(units,activation='relu'),\n",
    "                     Dropout(0.5),\n",
    "                     Dense(4, activation='softmax')]\n",
    "                     )\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    test_create_model(model)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the train_model function to train the text classification model with early stopping.\n",
    "\n",
    "- Set up an EarlyStopping callback:\n",
    "  - Monitor the validation loss ('val_loss').\n",
    "  - Set the patience to 3 epochs.\n",
    "  - Enable restoring the best weights.\n",
    "\n",
    "- Use the model.fit method to train the model:\n",
    "  - Pass the training data (train_data['Text']) and labels (train_data['Class'] - 1).\n",
    "  - Provide validation data using the validation_data parameter.\n",
    "  - Set the number of epochs to 20.\n",
    "  - Use a batch size of 32.\n",
    "  - Include the early stopping callback in the callbacks list.\n",
    "\n",
    "- Remember to subtract 1 from the class labels to make them 0-indexed, as required by the loss function.\n",
    "\n",
    "- Return the training history object for later analysis and visualization.\n",
    "\n",
    "- Consider adding a verbose parameter to control the output during training.\n",
    "\n",
    "- Ensure that the input data types match what the model expects (text data for inputs, integer labels for targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "def train_model(model, train_data, val_data, runtime_device):\n",
    "    # TODO: Define early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    with tf.device('/' + runtime_device + ':0'):\n",
    "        # YOUR CODE GOES HERE\n",
    "        train_texts = train_data['Text'].values\n",
    "        train_labels = train_data['Class'].values - 1\n",
    "        val_texts = val_data['Text'].values\n",
    "        val_labels = val_data['Class'].values - 1\n",
    "        history =model.fit(train_texts,train_labels,validation_data=(val_texts,val_labels),\n",
    "                           epochs=20,batch_size=32,callbacks=[early_stopping],verbose=1)\n",
    "        \n",
    "\n",
    "\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "    test_train_model(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Hints:**\n",
    "\n",
    "Complete the evaluate_model function to assess the performance of the trained model on the test data.\n",
    "\n",
    "- Use model.evaluate to compute the loss and accuracy on the test set:\n",
    "  - Pass the test data (test_data['Text']) and labels (test_data['Class'] - 1).\n",
    "  - Remember to subtract 1 from the class labels to make them 0-indexed.\n",
    "  - Print the test accuracy with 4 decimal places.\n",
    "\n",
    "- Generate predictions using model.predict:\n",
    "  - Use the test data (test_data['Text']) as input.\n",
    "  - Convert the predicted probabilities to class labels using np.argmax.\n",
    "\n",
    "- Create a classification report:\n",
    "  - Use sklearn's classification_report function.\n",
    "  - Compare the true labels (test_data['Class'] - 1) with the predicted classes.\n",
    "  - Print the classification report, which includes precision, recall, and F1-score for each class.\n",
    "\n",
    "- Return the predicted classes for further analysis or visualization.\n",
    "\n",
    "- Consider adding additional evaluation metrics if needed, such as confusion matrix or ROC AUC score.\n",
    "\n",
    "- Ensure that the input data types match what the model expects (text data for inputs, integer labels for targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "from sklearn.metrics import classification_report\n",
    "def evaluate_model(model, test_data):\n",
    "    \n",
    "    # TODO: Evaluate the model on the test data\n",
    "    test_texts = test_data['Text'].values\n",
    "    test_labels = test_data['Class'].values - 1\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_texts, test_labels, verbose=0)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # TODO: Make predictions on the test data\n",
    "    predictions=model.predict(test_texts)\n",
    "    # TODO: Convert the predictions to class labels\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    print(classification_report(test_data['Class'] - 1, predicted_classes))\n",
    "    \n",
    "    test_evaluate_model(predicted_classes)\n",
    "    \n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code to run the built pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n",
      "Downloading AG News dataset...\n",
      "Dataset loaded successfully.\n",
      "vectorize_text test passed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " text_vectorization_1             (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                                                    \n",
       "\n",
       " embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " self_attention_2                 ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)                                                        \n",
       "\n",
       " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              ?                                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ?                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " text_vectorization_1             (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mTextVectorization\u001b[0m)                                                    \n",
       "\n",
       " embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)          ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                    ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " self_attention_2                 ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       " (\u001b[38;5;33mSelfAttention\u001b[0m)                                                        \n",
       "\n",
       " dense_11 (\u001b[38;5;33mDense\u001b[0m)                 ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              ?                                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_12 (\u001b[38;5;33mDense\u001b[0m)                 ?                         \u001b[38;5;34m0\u001b[0m (unbuilt) \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_model test passed\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m1565/3000\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:20\u001b[0m 98ms/step - accuracy: 0.7513 - loss: 0.6298"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history, test_data, predicted_classes\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     history, test_data, predicted_classes \u001b[38;5;241m=\u001b[39m main()\n",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(vectorize_layer)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m train_model(model, train_data, val_data, device)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_data)\n",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_data, val_data, runtime_device)\u001b[0m\n\u001b[0;32m     14\u001b[0m     val_texts \u001b[38;5;241m=\u001b[39m val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m     val_labels \u001b[38;5;241m=\u001b[39m val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 16\u001b[0m     history \u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(train_texts,train_labels,validation_data\u001b[38;5;241m=\u001b[39m(val_texts,val_labels),\n\u001b[0;32m     17\u001b[0m                        epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[early_stopping],verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# YOUR CODE ENDS HERE\u001b[39;00m\n\u001b[0;32m     23\u001b[0m test_train_model(history)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\arj64\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#---------------- Do not change the code below ----------------#\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = detect_and_set_device()\n",
    "    # Load and preprocess data\n",
    "    train_data, test_data = load_data()\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create vectorization layer\n",
    "    vectorize_layer = vectorize_text(train_data, test_data)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = create_model(vectorize_layer)\n",
    "    \n",
    "    # Train model\n",
    "    history = train_model(model, train_data, val_data, device)\n",
    "    \n",
    "    # Evaluate model\n",
    "    predicted_classes = evaluate_model(model, test_data)\n",
    "    \n",
    "    return history, test_data, predicted_classes\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    history, test_data, predicted_classes = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------- Do not change the code below ----------------#\n",
    "# Run this cell to visualize results\n",
    "plot_results(history, test_data, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
